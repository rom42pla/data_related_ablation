{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "wandb.login()\n",
    "api = wandb.Api()\n",
    "experiments = api.runs(\"rom42pla_team/noisy_eeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_rows = []\n",
    "for experiment in experiments:\n",
    "    date, hour, dataset, validation, signal_type, model = experiment.name.split(\n",
    "        \"_\")\n",
    "    df_experiment = experiment.history()\n",
    "    runs = {col.split(\"-\")[0] for col in df_experiment.columns if re.fullmatch(r\"run_[0-9]+-.*\", col)}\n",
    "    avg_rows = []\n",
    "    for run in runs:\n",
    "        # prints all columns with the metrics of the run\n",
    "        metrics = {col for col in df_experiment.columns if re.fullmatch(f\"{run}-.*/.*\", col)}\n",
    "        # get the results for the run\n",
    "        metrics_val = {col for col in df_experiment.columns if re.fullmatch(f\"{run}-.*/val\", col)}\n",
    "        # gets the subset of dataframe for the run\n",
    "        df_run = df_experiment[sorted(metrics_val)].dropna().reset_index(drop=True)\n",
    "        df_run = df_run.rename(columns={col: col.split(\"-\")[-1].split(\"/\")[0] for col in df_run})\n",
    "        # drop columns that end with \"loss\"\n",
    "        df_run = df_run.loc[:, ~df_run.columns.str.endswith(\"loss\")]\n",
    "        # gets the best run based on the cls accuracy\n",
    "        df_run = df_run.replace(\"NaN\", None)\n",
    "        best_row_i = df_run[\"cls_acc\"].idxmax()\n",
    "        best_row = df_run.iloc[best_row_i]\n",
    "        avg_rows.append(best_row)\n",
    "    df_rows = pd.DataFrame(avg_rows)\n",
    "    rows_mean, rows_std = df_rows.mean(), df_rows.std()\n",
    "    models_renamed = {\n",
    "        \"linear\": \"Linear\",\n",
    "        \"mlp\": \"MLP\",\n",
    "        \"eegnet\": \"EEGNet\\cite{eegnet}\",\n",
    "        \"edpnet\": \"EDPNet\\cite{edpnet}\",\n",
    "        \"dino\": \"DINOv2\\cite{dinov2}\",\n",
    "        \"sateer\": \"SATEER\\cite{sateer}\",\n",
    "    }\n",
    "    validation_renamed = {\n",
    "        \"kfold\": \"$k$-fold\",\n",
    "        \"loso\": \"LOSO\"\n",
    "    }\n",
    "    for df in [rows_mean, rows_std]:\n",
    "        df[\"dataset\"] = dataset\n",
    "        df[\"validation\"] = validation_renamed[validation]\n",
    "        df[\"signal_type\"] = (\n",
    "            \"$<$\\\\SI{100}{\\\\hertz}\" if signal_type == \"eeg\" else \"$>$\\\\SI{100}{\\\\hertz}\"\n",
    "        )\n",
    "        df[\"model\"] = models_renamed[model]\n",
    "    rows = pd.DataFrame({\n",
    "        key: f\"{mean * 100:.1f} ± {std*100:.2f}\" if isinstance(mean, float) else mean\n",
    "        for key, mean, std in zip(rows_mean.index, rows_mean, rows_std)\n",
    "    }, index=[0]).iloc[0]\n",
    "    table_rows.append(rows)\n",
    "# merge each run's series\n",
    "table = pd.DataFrame(table_rows, dtype=\"object\")\n",
    "# reorder the columns\n",
    "first_cols = [\n",
    "    \"dataset\",\n",
    "    \"model\",\n",
    "    \"validation\",\n",
    "    \"signal_type\",\n",
    "]\n",
    "table = table.sort_values(first_cols)\n",
    "table = table[first_cols +\n",
    "              [col for col in table.columns if col not in first_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_for_latex(df, title=None):\n",
    "    latex_string = df.to_latex(na_rep=\"-\", index=False)\n",
    "    replacers = {\n",
    "        \"bottomrule\": \"botrule\",\n",
    "        \"midrule\": \"hline\",\n",
    "    }\n",
    "    for k, v in replacers.items():\n",
    "        latex_string = latex_string.replace(k, v)\n",
    "    if title:\n",
    "        print(title)\n",
    "    print(latex_string)\n",
    "    return latex_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGREGATED TABLE FOR deap:\n",
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "Model & Validation & cls Accuracy (\\%) $\\uparrow$ $<$\\SI{100}{\\hertz} & cls Accuracy (\\%) $\\uparrow$ $>$\\SI{100}{\\hertz} & cls $F_1$ (\\%) $\\uparrow$ $<$\\SI{100}{\\hertz} & cls $F_1$ (\\%) $\\uparrow$ $>$\\SI{100}{\\hertz} & ids Accuracy (\\%) $\\uparrow$ $<$\\SI{100}{\\hertz} & ids Accuracy (\\%) $\\uparrow$ $>$\\SI{100}{\\hertz} & ids $F_1$ (\\%) $\\uparrow$ $<$\\SI{100}{\\hertz} & ids $F_1$ (\\%) $\\uparrow$ $>$\\SI{100}{\\hertz} \\\\\n",
      "\\hline\n",
      "$k$-fold & DINOv2\\cite{dinov2} & 99.7 ± 0.08 & 99.8 ± 0.07 & 99.8 ± 0.07 & 99.8 ± 0.06 & 99.9 ± 0.05 & 99.9 ± 0.05 & 99.9 ± 0.05 & 99.9 ± 0.05 \\\\\n",
      "$k$-fold & EDPNet\\cite{edpnet} & 62.7 ± 0.58 & 68.5 ± 0.86 & 71.2 ± 1.07 & 75.1 ± 0.87 & 98.4 ± 0.39 & 99.4 ± 0.18 & 98.4 ± 0.39 & 99.4 ± 0.18 \\\\\n",
      "$k$-fold & EEGNet\\cite{eegnet} & 59.9 ± 0.72 & 61.0 ± 0.43 & 71.0 ± 0.91 & 71.6 ± 0.54 & 74.7 ± 14.83 & 96.7 ± 0.67 & 74.7 ± 14.83 & 96.7 ± 0.67 \\\\\n",
      "$k$-fold & Linear & 64.4 ± 0.67 & 63.8 ± 0.62 & 72.6 ± 0.90 & 73.0 ± 0.82 & 96.5 ± 0.35 & 95.8 ± 0.55 & 96.5 ± 0.35 & 95.8 ± 0.55 \\\\\n",
      "$k$-fold & MLP & 72.3 ± 0.71 & 72.9 ± 0.64 & 77.3 ± 1.29 & 77.7 ± 1.37 & 99.0 ± 0.14 & 99.5 ± 0.15 & 99.0 ± 0.14 & 99.5 ± 0.15 \\\\\n",
      "$k$-fold & SATEER\\cite{sateer} & 93.4 ± 0.62 & 91.1 ± 0.84 & 94.4 ± 0.53 & 92.4 ± 0.72 & 99.7 ± 0.10 & 99.7 ± 0.23 & 99.7 ± 0.10 & 99.7 ± 0.23 \\\\\n",
      "LOSO & DINOv2\\cite{dinov2} & 56.9 ± 3.72 & 57.2 ± 4.05 & 62.3 ± 8.16 & 61.4 ± 10.78 & - & - & - & - \\\\\n",
      "LOSO & EDPNet\\cite{edpnet} & 58.9 ± 5.55 & 57.9 ± 5.38 & 68.7 ± 8.33 & 68.1 ± 6.61 & - & - & - & - \\\\\n",
      "LOSO & EEGNet\\cite{eegnet} & 58.9 ± 5.38 & 57.6 ± 5.04 & 69.3 ± 7.52 & 67.3 ± 7.03 & - & - & - & - \\\\\n",
      "LOSO & Linear & 59.7 ± 5.07 & 58.6 ± 5.85 & 69.2 ± 8.00 & 68.5 ± 8.74 & - & - & - & - \\\\\n",
      "LOSO & MLP & 59.7 ± 5.29 & 57.3 ± 5.30 & 67.7 ± 9.14 & 65.9 ± 9.21 & - & - & - & - \\\\\n",
      "LOSO & SATEER\\cite{sateer} & 69.2 ± nan & - & 78.9 ± nan & - & - & - & - & - \\\\\n",
      "\\botrule\n",
      "\\end{tabular}\n",
      "\n",
      "INDIVIDUAL LABELS TABLES FOR DATASET deap:\n",
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "Model & Validation & Arousal $F_1$ $<$\\SI{100}{\\hertz} & Arousal $F_1$ $>$\\SI{100}{\\hertz} & Dominance $F_1$ $<$\\SI{100}{\\hertz} & Dominance $F_1$ $>$\\SI{100}{\\hertz} & Liking $F_1$ $<$\\SI{100}{\\hertz} & Liking $F_1$ $>$\\SI{100}{\\hertz} & Valence $F_1$ $<$\\SI{100}{\\hertz} & Valence $F_1$ $>$\\SI{100}{\\hertz} \\\\\n",
      "\\hline\n",
      "$k$-fold & DINOv2\\cite{dinov2} & 99.7 ± 0.13 & 99.8 ± 0.12 & 99.8 ± 0.10 & 99.8 ± 0.09 & 99.8 ± 0.07 & 99.9 ± 0.07 & 99.7 ± 0.06 & 99.8 ± 0.09 \\\\\n",
      "$k$-fold & EDPNet\\cite{edpnet} & 69.2 ± 2.00 & 73.7 ± 0.87 & 68.8 ± 1.56 & 72.6 ± 1.32 & 78.8 ± 0.92 & 81.5 ± 0.89 & 64.9 ± 2.01 & 70.6 ± 1.37 \\\\\n",
      "$k$-fold & EEGNet\\cite{eegnet} & 67.6 ± 1.54 & 68.1 ± 0.80 & 67.9 ± 1.05 & 68.6 ± 0.77 & 80.4 ± 0.90 & 80.1 ± 0.76 & 65.2 ± 1.59 & 66.8 ± 1.32 \\\\\n",
      "$k$-fold & Linear & 70.6 ± 1.92 & 70.7 ± 1.03 & 69.7 ± 1.04 & 70.7 ± 0.81 & 80.3 ± 1.02 & 80.7 ± 0.97 & 66.5 ± 1.58 & 66.7 ± 1.98 \\\\\n",
      "$k$-fold & MLP & 76.1 ± 2.43 & 76.2 ± 2.54 & 75.7 ± 2.48 & 76.0 ± 2.56 & 82.4 ± 0.89 & 83.6 ± 0.81 & 72.9 ± 2.55 & 72.4 ± 2.78 \\\\\n",
      "$k$-fold & SATEER\\cite{sateer} & 94.0 ± 0.65 & 92.0 ± 0.91 & 93.7 ± 0.68 & 92.3 ± 0.82 & 95.9 ± 0.59 & 93.6 ± 1.11 & 93.4 ± 1.03 & 91.5 ± 1.35 \\\\\n",
      "LOSO & DINOv2\\cite{dinov2} & 55.3 ± 19.96 & 54.0 ± 19.26 & 53.6 ± 18.08 & 51.8 ± 18.35 & 66.7 ± 11.79 & 65.5 ± 14.50 & 52.4 ± 18.14 & 51.8 ± 18.32 \\\\\n",
      "LOSO & EDPNet\\cite{edpnet} & 62.3 ± 19.45 & 57.3 ± 21.83 & 60.7 ± 18.72 & 61.7 ± 13.88 & 76.6 ± 10.15 & 70.0 ± 17.72 & 58.7 ± 13.61 & 57.9 ± 10.70 \\\\\n",
      "LOSO & EEGNet\\cite{eegnet} & 61.7 ± 18.71 & 54.8 ± 23.53 & 54.5 ± 14.52 & 55.2 ± 17.57 & 72.7 ± 10.23 & 70.4 ± 10.01 & 57.5 ± 13.47 & 50.3 ± 15.08 \\\\\n",
      "LOSO & Linear & 61.0 ± 17.93 & 46.4 ± 28.04 & 59.4 ± 15.82 & 43.1 ± 24.18 & 75.9 ± 10.30 & 69.9 ± 17.30 & 57.2 ± 15.65 & 45.3 ± 21.99 \\\\\n",
      "LOSO & MLP & 59.0 ± 20.26 & 55.8 ± 24.49 & 54.0 ± 20.67 & 53.9 ± 23.25 & 73.7 ± 8.49 & 70.9 ± 15.33 & 55.0 ± 18.26 & 55.0 ± 17.62 \\\\\n",
      "LOSO & SATEER\\cite{sateer} & 72.2 ± nan & - & 75.2 ± nan & - & 93.2 ± nan & - & 53.7 ± nan & - \\\\\n",
      "\\botrule\n",
      "\\end{tabular}\n",
      "\n",
      "INDIVIDUAL LABELS TABLES FOR DATASET deap:\n",
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "Model & Validation & Arousal acc. $<$\\SI{100}{\\hertz} & Arousal acc. $>$\\SI{100}{\\hertz} & Dominance acc. $<$\\SI{100}{\\hertz} & Dominance acc. $>$\\SI{100}{\\hertz} & Liking acc. $<$\\SI{100}{\\hertz} & Liking acc. $>$\\SI{100}{\\hertz} & Valence acc. $<$\\SI{100}{\\hertz} & Valence acc. $>$\\SI{100}{\\hertz} \\\\\n",
      "\\hline\n",
      "$k$-fold & DINOv2\\cite{dinov2} & 99.7 ± 0.15 & 99.8 ± 0.13 & 99.7 ± 0.11 & 99.8 ± 0.10 & 99.7 ± 0.10 & 99.8 ± 0.09 & 99.7 ± 0.06 & 99.8 ± 0.10 \\\\\n",
      "$k$-fold & EDPNet\\cite{edpnet} & 62.9 ± 1.39 & 68.1 ± 1.00 & 61.0 ± 0.59 & 67.7 ± 1.01 & 66.9 ± 1.23 & 72.1 ± 1.12 & 59.9 ± 1.25 & 66.2 ± 0.95 \\\\\n",
      "$k$-fold & EEGNet\\cite{eegnet} & 59.0 ± 1.01 & 60.2 ± 0.83 & 57.4 ± 0.75 & 59.5 ± 0.41 & 67.5 ± 1.24 & 67.4 ± 1.03 & 55.6 ± 1.19 & 56.9 ± 0.96 \\\\\n",
      "$k$-fold & Linear & 63.8 ± 1.14 & 64.2 ± 0.55 & 63.1 ± 1.21 & 61.5 ± 0.49 & 68.1 ± 1.32 & 68.3 ± 1.28 & 62.6 ± 0.65 & 61.2 ± 0.92 \\\\\n",
      "$k$-fold & MLP & 72.5 ± 1.28 & 72.2 ± 1.27 & 71.7 ± 1.41 & 72.8 ± 1.17 & 74.1 ± 0.96 & 75.8 ± 0.91 & 70.9 ± 1.08 & 70.9 ± 0.97 \\\\\n",
      "$k$-fold & SATEER\\cite{sateer} & 93.3 ± 0.79 & 90.9 ± 0.97 & 92.9 ± 0.75 & 91.3 ± 1.03 & 94.4 ± 0.82 & 91.4 ± 1.29 & 92.9 ± 1.10 & 90.6 ± 1.52 \\\\\n",
      "LOSO & DINOv2\\cite{dinov2} & 56.0 ± 8.71 & 55.6 ± 8.90 & 55.8 ± 9.35 & 55.4 ± 9.53 & 59.4 ± 9.55 & 58.8 ± 10.80 & 56.4 ± 6.14 & 57.8 ± 6.68 \\\\\n",
      "LOSO & EDPNet\\cite{edpnet} & 57.2 ± 14.03 & 55.9 ± 13.89 & 55.6 ± 11.97 & 56.7 ± 11.73 & 66.6 ± 12.03 & 61.8 ± 14.85 & 56.1 ± 6.15 & 53.7 ± 7.17 \\\\\n",
      "LOSO & EEGNet\\cite{eegnet} & 58.1 ± 12.01 & 55.1 ± 13.68 & 51.6 ± 9.77 & 53.7 ± 11.67 & 63.4 ± 10.23 & 61.0 ± 10.64 & 54.3 ± 5.89 & 54.0 ± 6.77 \\\\\n",
      "LOSO & Linear & 56.6 ± 12.92 & 55.2 ± 14.05 & 55.0 ± 10.10 & 52.2 ± 10.60 & 66.2 ± 11.84 & 62.7 ± 14.49 & 57.1 ± 8.27 & 53.0 ± 9.72 \\\\\n",
      "LOSO & MLP & 58.1 ± 11.86 & 56.2 ± 13.55 & 54.8 ± 11.19 & 55.4 ± 11.54 & 63.7 ± 10.05 & 63.0 ± 13.10 & 57.1 ± 8.13 & 54.9 ± 8.86 \\\\\n",
      "LOSO & SATEER\\cite{sateer} & 63.1 ± nan & - & 66.2 ± nan & - & 90.8 ± nan & - & 52.5 ± nan & - \\\\\n",
      "\\botrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in table[\"dataset\"].unique():\n",
    "    dataset_table = table[table[\"dataset\"] == dataset]\n",
    "    dataset_table = dataset_table.drop(columns=[\"dataset\"])\n",
    "    common_columns_raw = [\"model\", \"validation\", \"signal_type\"]\n",
    "    dataset_table = dataset_table.sort_values(by=common_columns_raw)\n",
    "    common_columns_renamed = [\n",
    "        \"Validation\",\n",
    "        \"Model\",\n",
    "        \"Frequencies\",\n",
    "    ]\n",
    "    dataset_table = dataset_table.rename(\n",
    "        columns={\n",
    "            k: v\n",
    "            for k, v in zip(common_columns_raw, common_columns_renamed)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # general table\n",
    "    agg_table_columns_raw = [\"cls_acc\", \"cls_f1\", \"ids_acc\", \"ids_f1\"]\n",
    "    agg_table = dataset_table[common_columns_renamed + agg_table_columns_raw]\n",
    "    agg_table_columns_renamed = [\n",
    "        \"cls Accuracy (\\\\%) $\\\\uparrow$\",\n",
    "        \"cls $F_1$ (\\\\%) $\\\\uparrow$\",\n",
    "        \"ids Accuracy (\\\\%) $\\\\uparrow$\",\n",
    "        \"ids $F_1$ (\\\\%) $\\\\uparrow$\",\n",
    "    ]\n",
    "    agg_table = agg_table.rename(\n",
    "        columns={\n",
    "            k: v\n",
    "            for k, v in zip(agg_table_columns_raw, agg_table_columns_renamed)\n",
    "        }\n",
    "    )\n",
    "    # print_df_for_latex(agg_table, title=f\"AGGREGATED TABLE 1 FOR {dataset}:\")\n",
    "    # now remove the frequencies column\n",
    "    agg_table = agg_table.pivot(index=[\"Model\", \"Validation\"], columns=\"Frequencies\")\n",
    "    agg_table.columns = [f\"{col[0]} {col[1]}\" for col in agg_table.columns]\n",
    "    agg_table = agg_table.reset_index()\n",
    "    print_df_for_latex(agg_table, title=f\"AGGREGATED TABLE FOR {dataset}:\")\n",
    "\n",
    "    # single labels\n",
    "    labels = sorted(set(re.findall(r\"cls_label=([a-zA-Z]+)_\", \" \".join(dataset_table.columns))))\n",
    "    labels_table_columns_raw = sorted([f\"cls_label={label}_{metric}\" for metric in [\"acc\", \"f1\"] for label in labels])\n",
    "    assert all([label in dataset_table.columns for label in labels_table_columns_raw])\n",
    "    labels_table = dataset_table[common_columns_renamed + labels_table_columns_raw]\n",
    "    metrics_renamed = {\"acc\": \"acc.\", \"f1\": \"$F_1$\"}\n",
    "    labels_table_columns_renamed = []\n",
    "    for column in labels_table_columns_raw:\n",
    "        _, label, metric = column.split(\"_\")\n",
    "        label = label.split(\"=\")[-1]\n",
    "        labels_table_columns_renamed.append(f\"{label.capitalize()} {metrics_renamed[metric]}\")\n",
    "    labels_table = labels_table.rename(\n",
    "        columns={k: v for k, v in zip(labels_table_columns_raw, labels_table_columns_renamed)}\n",
    "    )\n",
    "    frequencies = sorted(dataset_table[\"Frequencies\"].unique())\n",
    "    # since there are too many columns, we split the table into multiple tables\n",
    "    for metric in sorted(metrics_renamed.values()):\n",
    "        # labels_subtable = labels_table[common_columns_renamed]\n",
    "        columns_per_label = [column for column in labels_table.columns if metric in column]        \n",
    "        labels_subtable = labels_table[common_columns_renamed + columns_per_label]\n",
    "        # now remove the frequencies column\n",
    "        labels_subtable = labels_subtable.pivot(index=[\"Model\", \"Validation\"], columns=\"Frequencies\")\n",
    "        labels_subtable.columns = [f\"{col[0]} {col[1]}\" for col in labels_subtable.columns]\n",
    "        labels_subtable = labels_subtable.reset_index()\n",
    "        print_df_for_latex(labels_subtable, f\"INDIVIDUAL LABELS TABLES FOR DATASET {dataset}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
